{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfzVozrJEtVm"
      },
      "source": [
        "## Import necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu4T0eGO3Xvt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WM2swCDD4A51"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTm3Y60zpetx",
        "outputId": "941e3501-ffaa-47ed-e8b3-c97f71226bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions to read the API, parse and store json data retunred from the API."
      ],
      "metadata": {
        "id": "FvCdcQGgtY4c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Don2WvAGRn8"
      },
      "outputs": [],
      "source": [
        "def get_taxi_avail():\n",
        "  url = \"https://api.data.gov.sg/v1/transport/taxi-availability\"\n",
        "\n",
        "  # Send request and get response\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code != 200:\n",
        "    return\n",
        "\n",
        "  # Parse JSON data\n",
        "  data = response.json()\n",
        "\n",
        "  data_coordinates = data['features'][0]['geometry']['coordinates']\n",
        "  df_coordinates = pd.DataFrame(data_coordinates)\n",
        "  df_coordinates.columns = [\"LONGITUDE\", \"LATITUDE\"]\n",
        "\n",
        "  ts = data['features'][0]['properties']['timestamp']\n",
        "  dt_object = datetime.fromisoformat(ts)\n",
        "\n",
        "  ts_date = dt_object.date()\n",
        "  ts_time = dt_object.time()\n",
        "  df_coordinates[\"DATE\"] = ts_date\n",
        "  df_coordinates[\"TIME\"] = ts_time\n",
        "\n",
        "  return df_coordinates\n",
        "\n",
        "# taxi_avail = get_taxi_avail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqVHYYUoOPKl"
      },
      "outputs": [],
      "source": [
        "def get_area_meta():\n",
        "  url = 'https://api.data.gov.sg/v1/environment/2-hour-weather-forecast'\n",
        "\n",
        "  # Send request and get response\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code != 200:\n",
        "    return\n",
        "\n",
        "  # Parse JSON data\n",
        "  data = response.json()\n",
        "  data_areameta = data['area_metadata']\n",
        "  df = pd.DataFrame(data_areameta)\n",
        "  latitude_values = df['label_location'].apply(lambda x: x['latitude'])\n",
        "  df['LATITUDE'] = latitude_values\n",
        "  longitude_values = df['label_location'].apply(lambda x: x['longitude'])\n",
        "  df['LONGITUDE'] = longitude_values\n",
        "  df = df.drop(columns=['label_location'])\n",
        "\n",
        "  return df\n",
        "\n",
        "# get_area_meta()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv_GVvn03btf"
      },
      "outputs": [],
      "source": [
        "def get_weather():\n",
        "  url = 'https://api.data.gov.sg/v1/environment/2-hour-weather-forecast'\n",
        "\n",
        "  # Send request and get response\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code != 200:\n",
        "    return\n",
        "\n",
        "  # Parse JSON data\n",
        "  data = response.json()\n",
        "\n",
        "  data_weather = data['items'][0]['forecasts']\n",
        "  df = pd.DataFrame(data_weather)\n",
        "  df.columns = [\"AREA\", \"FORECAST\"]\n",
        "\n",
        "  ts = data['items'][0]['timestamp']\n",
        "  df['timestamp'] = ts\n",
        "  upd_ts = data['items'][0]['update_timestamp']\n",
        "  df['update_timestamp'] = upd_ts\n",
        "  valid_start_ts = data['items'][0]['valid_period']['start']\n",
        "  df['valid_start'] = valid_start_ts\n",
        "  valid_end_ts = data['items'][0]['valid_period']['end']\n",
        "  df['valid_end'] = valid_end_ts\n",
        "\n",
        "  return df\n",
        "\n",
        "# get_weather()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper function for appending and reading pickle files."
      ],
      "metadata": {
        "id": "1YSIZeiZtu1P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a27YbKAgUk0G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def append_pkl(pkl_fp, to_add_df):\n",
        "  try:\n",
        "    df = pd.read_pickle(pkl_fp)\n",
        "  except FileNotFoundError:\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "  df = pd.concat([df, to_add_df], ignore_index=True)\n",
        "  df.to_pickle(pkl_fp)\n",
        "\n",
        "def read_pkl(pkl_fp):\n",
        "  df = pd.read_pickle(pkl_fp)\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zfObgytjaYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf22c7bb-eabe-494e-8da3-93d2ad14cd98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting haversine\n",
            "  Downloading haversine-2.8.1-py2.py3-none-any.whl (7.7 kB)\n",
            "Installing collected packages: haversine\n",
            "Successfully installed haversine-2.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install haversine"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to allocate Taxis to the nearest zone base on their coordinates."
      ],
      "metadata": {
        "id": "UT78XyYWtyWL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDCgAM-1FT14"
      },
      "outputs": [],
      "source": [
        "import haversine as hs;\n",
        "def get_zone(longitude, latitude):\n",
        "  position = (latitude, longitude)\n",
        "\n",
        "  area_metadata = [\n",
        "    {\n",
        "      \"name\": \"Ang Mo Kio\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.375,\n",
        "        \"longitude\": 103.839\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Bedok\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.321,\n",
        "        \"longitude\": 103.924\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Bishan\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.350772,\n",
        "        \"longitude\": 103.839\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Boon Lay\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.304,\n",
        "        \"longitude\": 103.701\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Bukit Batok\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.353,\n",
        "        \"longitude\": 103.754\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Bukit Merah\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.277,\n",
        "        \"longitude\": 103.819\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Bukit Panjang\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.362,\n",
        "        \"longitude\": 103.77195\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Bukit Timah\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.325,\n",
        "        \"longitude\": 103.791\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Central Water Catchment\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.38,\n",
        "        \"longitude\": 103.805\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Changi\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.357,\n",
        "        \"longitude\": 103.987\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Choa Chu Kang\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.377,\n",
        "        \"longitude\": 103.745\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Clementi\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.315,\n",
        "        \"longitude\": 103.76\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"City\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.292,\n",
        "        \"longitude\": 103.844\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Geylang\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.318,\n",
        "        \"longitude\": 103.884\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Hougang\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.361218,\n",
        "        \"longitude\": 103.886\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Jalan Bahar\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.347,\n",
        "        \"longitude\": 103.67\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Jurong East\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.326,\n",
        "        \"longitude\": 103.737\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Jurong Island\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.266,\n",
        "        \"longitude\": 103.699\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Jurong West\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.34039,\n",
        "        \"longitude\": 103.705\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Kallang\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.312,\n",
        "        \"longitude\": 103.862\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Lim Chu Kang\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.423,\n",
        "        \"longitude\": 103.717332\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Mandai\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.419,\n",
        "        \"longitude\": 103.812\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Marine Parade\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.297,\n",
        "        \"longitude\": 103.891\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Novena\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.327,\n",
        "        \"longitude\": 103.826\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Pasir Ris\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.37,\n",
        "        \"longitude\": 103.948\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Paya Lebar\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.358,\n",
        "        \"longitude\": 103.914\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Pioneer\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.315,\n",
        "        \"longitude\": 103.675\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Pulau Tekong\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.403,\n",
        "        \"longitude\": 104.053\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Pulau Ubin\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.404,\n",
        "        \"longitude\": 103.96\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Punggol\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.401,\n",
        "        \"longitude\": 103.904\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Queenstown\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.291,\n",
        "        \"longitude\": 103.78576\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Seletar\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.404,\n",
        "        \"longitude\": 103.869\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Sembawang\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.445,\n",
        "        \"longitude\": 103.818495\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Sengkang\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.384,\n",
        "        \"longitude\": 103.891443\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Sentosa\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.243,\n",
        "        \"longitude\": 103.832\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Serangoon\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.357,\n",
        "        \"longitude\": 103.865\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Southern Islands\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.208,\n",
        "        \"longitude\": 103.842\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Sungei Kadut\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.413,\n",
        "        \"longitude\": 103.756\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Tampines\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.345,\n",
        "        \"longitude\": 103.944\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Tanglin\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.308,\n",
        "        \"longitude\": 103.813\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Tengah\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.374,\n",
        "        \"longitude\": 103.715\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Toa Payoh\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.334304,\n",
        "        \"longitude\": 103.856327\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Tuas\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.294947,\n",
        "        \"longitude\": 103.635\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Western Islands\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.205926,\n",
        "        \"longitude\": 103.746\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Western Water Catchment\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.405,\n",
        "        \"longitude\": 103.689\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Woodlands\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.432,\n",
        "        \"longitude\": 103.786528\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Yishun\",\n",
        "      \"label_location\": {\n",
        "        \"latitude\": 1.418,\n",
        "        \"longitude\": 103.839\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "\n",
        "  shortest_dist = {\"Area\": \"NULL\", \"Distance\": 6000000}\n",
        "\n",
        "  for zone in area_metadata:\n",
        "    compare = (zone['label_location']['latitude'], zone['label_location']['longitude'])\n",
        "    dist = hs.haversine(compare, position)\n",
        "    #See if it is the shortest distance\n",
        "    if dist < shortest_dist['Distance']:\n",
        "      shortest_dist['Area'] = zone['name']\n",
        "      shortest_dist['Distance'] = dist\n",
        "\n",
        "  return shortest_dist['Area']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start of Data Cleaning.\n",
        "## Removing data points that are out of our date range.\n",
        "Range of our dates used is from 15/03/2024 to 04/04/2024."
      ],
      "metadata": {
        "id": "N8lhMwmGjIvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read pkl files\n",
        "taxi_df = read_pkl(\"taxi_log.pkl\")\n",
        "weather_df = read_pkl(\"weather_log_final.pkl\")\n",
        "\n",
        "# Remove rows from taxi_df\n",
        "taxi_df.drop(taxi_df[((taxi_df['DATE'] == '2024-04-05') | (taxi_df['DATE'] == '2024-03-14'))].index, inplace=True)\n",
        "\n",
        "# Remove rows from weather_df\n",
        "weather_df.drop(weather_df[((weather_df['weather_date'] == '2024-04-05') | (weather_df['weather_date'] == '2024-03-14'))].index, inplace=True)"
      ],
      "metadata": {
        "id": "FcIMXwL2jHMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y77PoqAWp7zB"
      },
      "source": [
        "\n",
        "## Adding Zones to Taxi Dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rt5-k6QqB3l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "eac0574d-77ea-48d1-e534-09651ae8c76d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'taxi_data.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f28dff87d65a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Read Taxi pkl file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtaxi_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_pkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"taxi_data.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_taxi_zones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtaxi_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Zone'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtaxi_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_zone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LONGITUDE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LATITUDE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-7475b89506b3>\u001b[0m in \u001b[0;36mread_pkl\u001b[0;34m(pkl_fp)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_pkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \"\"\"\n\u001b[1;32m    178\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'taxi_data.pkl'"
          ]
        }
      ],
      "source": [
        "def load_taxi_zones():\n",
        "  taxi_df['Zone'] = taxi_df.apply(lambda row: get_zone(row['LONGITUDE'], row['LATITUDE']), axis=1)\n",
        "  return taxi_df\n",
        "\n",
        "#Add Locaiton Zones to dataframe\n",
        "taxi_df = load_taxi_zones()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding days of the week to taxi Dataframe."
      ],
      "metadata": {
        "id": "KMHSC0VVocCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import calendar\n",
        "\n",
        "def add_day_of_week(df):\n",
        "  df['Day_of_Week'] = df['DATE'].apply(lambda x: calendar.day_name[x.weekday()])\n",
        "  return df\n",
        "\n",
        "#Add days of the week into dataframe\n",
        "taxi_df = add_day_of_week(taxi_df)\n",
        "taxi_df.groupby('Day_of_Week').size()"
      ],
      "metadata": {
        "id": "tYUljlQ2ofXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning of Weather Data."
      ],
      "metadata": {
        "id": "NYFHtfRjuSmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import time\n",
        "\n",
        "def clean_weather(df):\n",
        "    # Convert the 'timestamp' column to datetime\n",
        "    df['timestamp'] = pd.to_datetime(weather_df['timestamp'])\n",
        "    df['valid_start'] = pd.to_datetime(weather_df['valid_start'])\n",
        "    df['valid_end'] = pd.to_datetime(weather_df['valid_end'])\n",
        "\n",
        "    # Create new columns 'valid_start_date', 'valid_start_time', 'valid_end_date' and 'valid_end_time' by splitting the 'valid_start' and 'valid_end' columns]\n",
        "    df['weather_date'] = df['valid_start'].dt.date\n",
        "    df['weather_start_time'] = df['valid_start'].dt.time\n",
        "    df['weather_end_time'] = df['valid_end'].dt.time\n",
        "\n",
        "    # Assuming 'column_to_remove' is the name of the column you want to remove\n",
        "    df = df.drop('valid_start', axis=1)\n",
        "    df = df.drop('valid_end', axis=1)\n",
        "    df = df.drop('update_timestamp', axis=1)\n",
        "    # Remove duplicates\n",
        "    df = df.drop_duplicates()\n",
        "    # Filter rows where hour is divisible by 2 and minute is 0\n",
        "    df = df[df['weather_start_time'].apply(lambda x: x.hour % 2 == 0 and x.minute == 0)]\n",
        "\n",
        "    # Fixing the weather_start_time and weather_end_time for 12:00:00\n",
        "    for index, row in df.iterrows():\n",
        "        if row['timestamp'].hour == 12:\n",
        "            df.at[index,'weather_start_time'] = time(12, 0, 0)\n",
        "            df.at[index,'weather_end_time'] = time(14, 0, 0)\n",
        "    return df\n",
        "\n",
        "weather_df = clean_weather(weather_df)\n",
        "weather_df.to_csv('weather_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "DtZvQsTkjD70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions to further clean and prep the dataset."
      ],
      "metadata": {
        "id": "4aXXmydnupsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to check if a given time is between a start time and an end time\n",
        "def is_time_between(start_time, end_time, check_time):\n",
        "    # If start time is greater than end time, it means the time range crosses midnight\n",
        "    if start_time > end_time:\n",
        "        # If check time is not between end_time and start_time, return True\n",
        "        if check_time >= start_time or check_time <= end_time:\n",
        "            return True\n",
        "    # Else, the time range does not cross midnight\n",
        "    else:\n",
        "        # If check time is between start_time and end_time, return True\n",
        "        if start_time <= check_time <= end_time:\n",
        "            return True\n",
        "    # If none of the above conditions are met, return False\n",
        "    return False"
      ],
      "metadata": {
        "id": "FQp8QyxdjPhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to assign forecast to taxi_df\n",
        "def assign_forecast(taxi_df, weather_df):\n",
        "    # Create a new column 'FORECAST' in the taxi_df DataFrame\n",
        "    if 'FORECAST' not in taxi_df.columns:\n",
        "        taxi_df['FORECAST'] = np.nan\n",
        "\n",
        "    # Iterate through each row in the taxi_df DataFrame\n",
        "    for index, row in taxi_df.iterrows():\n",
        "\n",
        "        # Check if the 'FORECAST' column is already filled\n",
        "        if pd.notna(row['FORECAST']):\n",
        "            continue\n",
        "        # Rest of your code here\n",
        "\n",
        "        # Find the corresponding weather data\n",
        "        weather_data = weather_df[weather_df['weather_date'] == row['DATE']]\n",
        "\n",
        "        # Iterate through each row in the weather_data DataFrame\n",
        "        for _, weather_row in weather_data.iterrows():\n",
        "\n",
        "            # Check if the timestamp is between the start and end time\n",
        "            if is_time_between(weather_row['weather_start_time'], weather_row['weather_end_time'], row['TIME']) and row['AREA'] == weather_row['AREA']:\n",
        "                # Assign the forecast to the 'forecast' column in the taxi_df DataFrame\n",
        "                taxi_df.at[index, 'FORECAST'] = weather_row['FORECAST']\n",
        "                break\n",
        "        if(index % 100000 == 0):\n",
        "            # Save the DataFrame to a CSV file for every 100,000 rows as a safety measure\n",
        "            taxi_df.to_csv('taxi_data.csv', index=False)\n",
        "    return taxi_df\n",
        "\n",
        "taxi_df = assign_forecast(taxi_df, weather_df)\n",
        "taxi_df.head()\n"
      ],
      "metadata": {
        "id": "xcqmMmWLjQ4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to fix missing values in the 'FORECAST' column\n",
        "def fix_na(taxi_df):\n",
        "    for index, row in taxi_df.iterrows():\n",
        "\n",
        "        # Check if the 'FORECAST' column is already filled\n",
        "        if pd.notna(row['FORECAST']):\n",
        "            continue\n",
        "\n",
        "        if is_time_between('04:00:00', '06:00:00', row['TIME']) and row['DATE'] == '2024-03-19':\n",
        "            taxi_df.at[index, 'FORECAST'] = 'Partly Cloudy (Night)'\n",
        "\n",
        "        elif is_time_between('06:00:00', '08:00:00', row['TIME']) and row['DATE'] == '2024-03-19':\n",
        "            taxi_df.at[index, 'FORECAST'] = 'Partly Cloudy (Day)'\n",
        "\n",
        "        elif is_time_between('04:00:00', '06:00:00', row['TIME']) and row['DATE'] == '2024-03-24':\n",
        "            taxi_df.at[index, 'FORECAST'] = 'Partly Cloudy (Night)'\n",
        "\n",
        "        elif is_time_between('06:00:00', '12:00:00', row['TIME']) and row['DATE'] == '2024-03-24':\n",
        "            taxi_df.at[index, 'FORECAST'] = 'Partly Cloudy (Day)'\n",
        "\n",
        "        elif is_time_between('22:00:00', '00:00:00', row['TIME']) and row['DATE'] == '2024-03-29':\n",
        "            taxi_df.at[index, 'FORECAST'] = 'Partly Cloudy (Night)'\n",
        "\n",
        "fix_na(taxi_df)\n",
        "taxi_df.to_csv('taxi_data.csv', index=False)"
      ],
      "metadata": {
        "id": "qOnUe8k4jT5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to consolidate taxi data\n",
        "def consolidate_taxi_data(df):\n",
        "    consolidated_df = df.groupby(['AREA', 'FORECAST', 'DATE', 'TIME','Day_of_Week']).size().reset_index(name='Count')\n",
        "    consolidated_df.sort_values(['DATE', 'TIME'], inplace=True)\n",
        "    return consolidated_df\n",
        "\n",
        "# Use the function\n",
        "consolidated_taxi_df = consolidate_taxi_data(taxi_df)\n",
        "consolidated_taxi_df.to_csv('consolidated_taxi_data.csv', index=False)\n",
        "\n",
        "# Function to consolidate taxi data by the hour\n",
        "def consolidate_taxi_1hour(df):\n",
        "    df['TIME'] = pd.to_datetime(df['TIME']).dt.floor('h').dt.time\n",
        "    df = df.groupby(['AREA', 'FORECAST', 'DATE', 'TIME','Day_of_Week']).sum().reset_index()\n",
        "    df.sort_values(['DATE', 'TIME'], inplace=True)\n",
        "    return df\n",
        "\n",
        "consolidate_taxi_1hour_df = consolidate_taxi_1hour(consolidated_taxi_df)\n",
        "consolidate_taxi_1hour_df.to_csv('consolidated_taxi_1hour.csv', index=False)\n"
      ],
      "metadata": {
        "id": "4fDrc9i0jYr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odtenXz7pvjV"
      },
      "source": [
        "## Display Taxi Location on Matplot based on the day of the week."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvRGTw9ijI51"
      },
      "outputs": [],
      "source": [
        "from ipywidgets import interact\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "#Plot all Taxis using a scatter plot based on their cords, colour sperated by Zones.\n",
        "def plot_data_week(day_of_week):\n",
        "    if(day_of_week=='All'):\n",
        "        df_day = taxi_df\n",
        "    else:\n",
        "        # Filter data for the selected day of the week\n",
        "        df_day = taxi_df[taxi_df['Day_of_Week'] == day_of_week]\n",
        "\n",
        "    # Plot the data\n",
        "    plt.figure(figsize=(150, 75))\n",
        "    plt.scatter(df_day[\"LONGITUDE\"], df_day[\"LATITUDE\"], c=df_day[\"Zone\"].astype('category').cat.codes)\n",
        "\n",
        "    # Create a legend\n",
        "    zone_names = df_day[\"Zone\"].unique()\n",
        "    color_map = plt.cm.get_cmap('viridis', len(zone_names))\n",
        "    legend_elements = [mpatches.Patch(color=color_map(i), label=zone) for i, zone in enumerate(zone_names)]\n",
        "    plt.legend(handles=legend_elements, loc='upper right',fontsize=50, title='Zone', title_fontsize='50',markerscale=10)\n",
        "\n",
        "    plt.title(f'Taxi Data for {day_of_week}')\n",
        "    plt.xlabel('Longitude',fontsize=50)\n",
        "    plt.ylabel('Latitude',fontsize=50)\n",
        "    plt.title(label=f'Number of Taxis: {len(df_day)}', fontsize=50)\n",
        "    plt.show()\n",
        "\n",
        "# Create a slider for day of the week\n",
        "days_of_week = ['All','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "interact(plot_data_week, day_of_week=days_of_week)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Taxi Location on Matplot based on the weather."
      ],
      "metadata": {
        "id": "ZpOZTweiu33x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot all Taxis using a scatter plot based on the weather using their cords, colour sperated by Zones.\n",
        "def plot_data_weather(weather):\n",
        "    if(weather=='All'):\n",
        "        df_day = taxi_df\n",
        "    else:\n",
        "        # Filter data for the selected day of the week\n",
        "        df_day = taxi_df[taxi_df['FORECAST'] == weather]\n",
        "\n",
        "    # Plot the data\n",
        "    plt.figure(figsize=(150, 75))\n",
        "    plt.scatter(df_day[\"LONGITUDE\"], df_day[\"LATITUDE\"], c=df_day[\"AREA\"].astype('category').cat.codes)\n",
        "\n",
        "    # Create a legend\n",
        "    zone_names = df_day[\"AREA\"].unique()\n",
        "    color_map = plt.cm.get_cmap('viridis', len(zone_names))\n",
        "    legend_elements = [mpatches.Patch(color=color_map(i), label=zone) for i, zone in enumerate(zone_names)]\n",
        "    plt.legend(handles=legend_elements, loc='upper right',fontsize=50, title='Area', title_fontsize='50',markerscale=10)\n",
        "\n",
        "    plt.title(f'Taxi Data for {weather}')\n",
        "    plt.xlabel('Longitude',fontsize=50)\n",
        "    plt.ylabel('Latitude',fontsize=50)\n",
        "    plt.title(label=f'Number of Taxis: {len(df_day)}', fontsize=50)\n",
        "    plt.show()\n",
        "\n",
        "# Create a slider for day of the week\n",
        "weathers = ['All','Fair (Night)', 'Fair (Day)', 'Fair & Warm',\n",
        "       'Partly Cloudy (Night)', 'Thundery Showers', 'Partly Cloudy (Day)',\n",
        "       'Showers', 'Heavy Thundery Showers', 'Cloudy', 'Light Showers']\n",
        "interact(plot_data_weather, weather=weathers,s=50)"
      ],
      "metadata": {
        "id": "Zi872HpzobMi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}